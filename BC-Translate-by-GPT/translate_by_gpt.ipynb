{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import xml.etree.ElementTree as ET\n",
    "from colorama import Fore, Style\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv('OPENAI_API_KEY'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_promt = \"\"\"\n",
    "Act as an interpreter. Your task is translate given sentence to Chinese (simple chinese) language. Provide the translation only!\n",
    "Context : ERP system application translation.\n",
    "\n",
    "Do not translate below words:\n",
    "GQA, EOL, SOP, PWS, APQP, ...\n",
    "\"\"\"\n",
    "\n",
    "def translate(text):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_promt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        model = \"gpt-4o\",\n",
    "        temperature = 0.2,\n",
    "        max_tokens = 3000,\n",
    "        top_p = 0.1,\n",
    "        frequency_penalty = 0.2,\n",
    "        presence_penalty = 0.1,\n",
    "        stop = None\n",
    "    )\n",
    "\n",
    "    response_json = json.loads(chat_completion.model_dump_json(indent = 2))\n",
    "    content = response_json['choices'][0]['message']['content']\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you create a new translation please use this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Input file.g.xlf'\n",
    "output_file = 'Output file.g.zh-CN.xlf'\n",
    "language_code = 'zn-CN' #Target language code\n",
    "\n",
    "count = 0\n",
    "tree = ET.parse(input_file)\n",
    "ET.register_namespace('', 'urn:oasis:names:tc:xliff:document:1.2')\n",
    "root = tree.getroot()\n",
    "ns = {'xliff': 'urn:oasis:names:tc:xliff:document:1.2'}\n",
    "trans_unit = root.find('.//xliff:trans-unit', ns)\n",
    "\n",
    "\n",
    "for trans_unit in root.findall('.//xliff:trans-unit', ns):\n",
    "    trans_unit_id = trans_unit.attrib.get('id', '')\n",
    "    if (trans_unit_id.startswith('Page')) or (trans_unit_id.startswith('Report')) or (trans_unit_id.startswith('Codeunit')):\n",
    "        source = trans_unit.find('xliff:source', ns)\n",
    "        if source is not None:\n",
    "            target = trans_unit.find('xliff:target', ns)\n",
    "            if target is None:\n",
    "                target = ET.Element('target', attrib={'state': 'translated'})\n",
    "                trans_unit.append(target)\n",
    "            \n",
    "            if source.text:\n",
    "                target.text = translate(source.text)\n",
    "                count +=1\n",
    "                print(f\" Count : {count} Forrás : {source.text} -- {Fore.CYAN}Fordítás : {target.text}{Style.RESET_ALL} -- ID : {trans_unit_id}\")\n",
    "\n",
    "file_element = root.find('.//xliff:file', ns)\n",
    "if file_element is not None:\n",
    "    file_element.set('target-language', language_code)\n",
    "\n",
    "tree.write(output_file, encoding='utf-8', xml_declaration=True)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an existing translation please use this cell. In this case the existing translations will not send to GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Applications.g.xlf'  # Name of system generated xlf, this file created during build.\n",
    "existing_file = 'Applications.g.hu-HU.xlf'  # Existing translation file.\n",
    "output_file = 'Applications_translated.xlf'  # New translation file.\n",
    "language_code = 'hu-HU' # Code of target language.\n",
    "\n",
    "count = 0\n",
    "not_found_in_original = False\n",
    "\n",
    "tree_new = ET.parse(input_file)\n",
    "tree_existing = ET.parse(existing_file)\n",
    "\n",
    "ET.register_namespace('', 'urn:oasis:names:tc:xliff:document:1.2')\n",
    "\n",
    "root_new = tree_new.getroot()\n",
    "root_existing = tree_existing.getroot()\n",
    "\n",
    "ns = {'xliff': 'urn:oasis:names:tc:xliff:document:1.2'}\n",
    "\n",
    "existing_trans_units = {}\n",
    "\n",
    "for trans_unit in root_existing.findall('.//xliff:trans-unit', ns):\n",
    "    trans_unit_id = trans_unit.attrib.get('id')\n",
    "    target = trans_unit.find('xliff:target', ns)\n",
    "    existing_trans_units[trans_unit_id] = target.text if target is not None else None\n",
    "\n",
    "for trans_unit in root_new.findall('.//xliff:trans-unit', ns):\n",
    "    trans_unit_id = trans_unit.attrib.get('id', '')\n",
    "    if (trans_unit_id.startswith('Page')) or (trans_unit_id.startswith('Report'))  or (trans_unit_id.startswith('Codeunit')):\n",
    "        source = trans_unit.find('xliff:source', ns)\n",
    "        if source is not None:\n",
    "            if trans_unit_id in existing_trans_units:\n",
    "                existing_target_text = existing_trans_units[trans_unit_id]\n",
    "                if existing_target_text:\n",
    "                    target = trans_unit.find('xliff:target', ns)\n",
    "                    if target is None:\n",
    "                        target = ET.Element('target', attrib={'state': 'translated'})\n",
    "                        trans_unit.append(target)\n",
    "                    \n",
    "                    target.text = existing_target_text\n",
    "                    print(f\"{Fore.GREEN}ID: {trans_unit_id} átmásolva: {existing_target_text}{Style.RESET_ALL}\")\n",
    "                    continue  \n",
    "            else:\n",
    "                not_found_in_original = True\n",
    "\n",
    "            target = trans_unit.find('xliff:target', ns)\n",
    "            if target is None:\n",
    "                target = ET.Element('target', attrib={'state': 'translated'})\n",
    "                trans_unit.append(target)\n",
    "            \n",
    "            if source.text:\n",
    "                if (not target.text) or (not_found_in_original):\n",
    "                    target.text = translate(source.text)\n",
    "                    count += 1\n",
    "                    print(f\" Count: {count} Forrás: {source.text} -- {Fore.CYAN}Fordítás: {target.text}{Style.RESET_ALL} -- ID: {trans_unit_id}\")\n",
    "                    not_found_in_original = False\n",
    "\n",
    "file_element = root_new.find('.//xliff:file', ns)\n",
    "if file_element is not None:\n",
    "    file_element.set('target-language', language_code)\n",
    "\n",
    "tree_new.write(output_file, encoding='utf-8', xml_declaration=True)\n",
    "\n",
    "print(\"Finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
