{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extract\n",
    "import requests\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime as dt\n",
    "import boto3 #s3 funkciói ebben vannak\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "#1. egy T-2months taxi adat\n",
    "#2. egy T-2months időjárás adat\n",
    "#3. feltöltés az s3-ra (raw-data/to-processed/weather-data and raw-data/to-processed/taxi-data)\n",
    "#4. code refactor\n",
    "#5. create trigger\n",
    "\n",
    "def get_taxi_data(start_date: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Retrieves taxi data for a specified start date from the City of Chicago data portal.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): The start date in the format 'YYYY-MM-DD'. The function retrieves\n",
    "            taxi data for the specified date.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the retrieved taxi data. The data is retrieved from\n",
    "            the City of Chicago data portal based on the provided start date. Each entry\n",
    "            in the dictionary represents a taxi trip and includes various details such as\n",
    "            trip start timestamp, trip end timestamp, trip duration, pickup and dropoff\n",
    "            locations, fare details, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    url_new = f\"https://data.cityofchicago.org/resource/ajtu-isnz.json?$where=trip_start_timestamp >= '{start_date}T00:00:00' AND trip_start_timestamp <= '{start_date}T23:59:59'&$limit=213000000\"\n",
    "    response_taxi = requests.get(url_new)\n",
    "    taxi_data = response_taxi.json()\n",
    "    return taxi_data\n",
    "    \n",
    "def get_weather_data(weather_start_date: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Retrieves weather data for a specified start date from the Open-Meteo archive API.\n",
    "\n",
    "    Args:\n",
    "        weather_start_date (str): The start date in the format 'YYYY-MM-DD'. The function retrieves\n",
    "            weather data for the specified date.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing the retrieved weather data. The data is retrieved from\n",
    "            the Open-Meteo archive API based on the provided start date. The dictionary includes\n",
    "            various weather parameters such as temperature at 2 meters above ground level,\n",
    "            wind speed at 10 meters above ground level, precipitation, and rain.\n",
    "    \"\"\"\n",
    "    weather_url = f\"https://archive-api.open-meteo.com/v1/era5\"\n",
    "    params = {\n",
    "        \"latitude\" : 41.85,\n",
    "        \"longitude\" : -87.65,\n",
    "        \"start_date\" : weather_start_date,\n",
    "        \"end_date\" : weather_start_date,\n",
    "        \"hourly\" : \"temperature_2m,wind_speed_10m,precipitation,rain\"\n",
    "    }\n",
    "    response = requests.get(weather_url, params=params)\n",
    "    weather_data = response.json()\n",
    "    return weather_data\n",
    "\n",
    "def upload_data(bucket_name:str, bucket_key: str, bucket_data:Dict) -> None:\n",
    "    client = boto3.client('s3')\n",
    "    client.put_object(\n",
    "        Bucket = bucket_name,\n",
    "        Key = bucket_key,\n",
    "        Body = json.dumps(bucket_data)\n",
    "        )\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    startDate = (dt.now() - relativedelta(months=2)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    weather_bucket_key = f'raw_data/to_processed/weather_data/weather_raw{startDate}.json'\n",
    "    taxi_bucket_key = f\"raw_data/to_processed/taxi_data/taxi_raw{startDate}.json\"\n",
    "    bucket_name = 'chicago-taxi'\n",
    "    \n",
    "    taxi_data_api_call = get_taxi_data(startDate)\n",
    "    \n",
    "    weather_data_api_call = get_weather_data(startDate)\n",
    "    \n",
    "    upload_data(bucket_name, taxi_bucket_key, taxi_data_api_call)\n",
    "    upload_data(bucket_name, weather_bucket_key, weather_data_api_call)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation\n",
    "import json\n",
    "from io import StringIO\n",
    "import boto3\n",
    "import pandas as pd #A layersben hozzá kell adni!!\n",
    "\n",
    "def transform_weather_data(weather_data: json) -> pd.DataFrame:\n",
    "    \"\"\"Transform weather data from JSON format to a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    weather_data (json): JSON data containing weather information.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Transformed weather data in a DataFrame format.\n",
    "    \"\"\"\n",
    "    \n",
    "    weather_filtered = {\n",
    "        'datetime': weather_data['hourly']['time'],\n",
    "        'temperature' : weather_data['hourly']['temperature_2m'],\n",
    "        'wind' : weather_data['hourly']['wind_speed_10m'],\n",
    "        'precipitation' : weather_data['hourly']['precipitation'],\n",
    "        'rain' : weather_data['hourly']['rain']\n",
    "    }\n",
    "    weather_df = pd.DataFrame(weather_filtered)\n",
    "    weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])\n",
    "    return weather_df\n",
    "\n",
    "def taxi_trips_transformations(taxi_trips: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transformations for taxi trips DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - taxi_trips (pd.DataFrame): DataFrame containing taxi trips data.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Transformed DataFrame with specified columns dropped, NaN values removed,\n",
    "      columns renamed, and datetime rounded to the nearest hour for weather matching.\n",
    "    \"\"\"\n",
    "    if not isinstance(taxi_trips,pd.DataFrame):\n",
    "      raise TypeError('taxi_trips is not a valid data frame')\n",
    "    \n",
    "    taxi_trips.drop(['pickup_census_tract', 'dropoff_census_tract','pickup_centroid_location', 'dropoff_centroid_location'], axis=1, inplace=True)\n",
    "    taxi_trips.dropna(inplace=True)\n",
    "    taxi_trips.rename(columns={'pickup_community_area' : 'pickup_community_area_id',\n",
    "                            'dropoff_community_area' : 'dropoff_community_area_id'\n",
    "                            },inplace=True)\n",
    "    taxi_trips['datetime_for_weather'] = pd.to_datetime(taxi_trips['trip_start_timestamp']).dt.floor('h')\n",
    "    return taxi_trips\n",
    "    \n",
    "def update_master(taxi_trips : pd.DataFrame, master: pd.DataFrame, id_col_name:str, value_col_name:str) -> pd.DataFrame:\n",
    "    \"\"\"Update the master dataframe with new values from the taxi trips dataframe.\n",
    "    \n",
    "    Args:\n",
    "        taxi_trips (pd.DataFrame): The dataframe containing new values.\n",
    "        master (pd.DataFrame): The master dataframe to be updated.\n",
    "        id_col_name (str): The name of the column in the master dataframe that contains IDs.\n",
    "        value_col_name (str): The name of the column in the master dataframe that contains values.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The updated master dataframe with new values added.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_id = master[id_col_name].max()\n",
    "\n",
    "    new_values = [value for value in taxi_trips[value_col_name].values if value not in master[value_col_name].values]\n",
    "    \n",
    "    new_data_df = pd.DataFrame({\n",
    "        id_col_name : range(max_id + 1, max_id + len(new_values) + 1),\n",
    "        value_col_name : new_values\n",
    "    })\n",
    "\n",
    "    return pd.concat([master, new_data_df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "def read_csv_from_s3(bucket: str, path: str, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a CSV file from an Amazon S3 bucket into a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - bucket (str): The name of the Amazon S3 bucket.\n",
    "    - path (str): The path within the bucket where the CSV file is located.\n",
    "    - filename (str): The name of the CSV file to be read.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A Pandas DataFrame containing the data read from the CSV file.\n",
    "\n",
    "    Note:\n",
    "    - Requires the boto3 library to be installed.\n",
    "    - Assumes the CSV file is UTF-8 encoded.\n",
    "    \"\"\"\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    full_path = f'{path}{filename}'\n",
    "    \n",
    "    object = s3.get_object(Bucket=bucket, Key=full_path)\n",
    "    object = object['Body'].read().decode('utf-8')\n",
    "    \n",
    "    return pd.read_csv(StringIO(object))\n",
    "\n",
    "def update_taxi_trips_with_master_data(taxi_trips: pd.DataFrame, payment_type_master: pd.DataFrame, company_master: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Update taxi trips with master data.\n",
    "    \n",
    "    Parameters:\n",
    "    taxi_trips (pd.DataFrame): DataFrame containing taxi trips data.\n",
    "    payment_type_master (pd.DataFrame): DataFrame containing master data for payment types.\n",
    "    company_master (pd.DataFrame): DataFrame containing master data for companies.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Updated DataFrame with merged master data.\n",
    "    \"\"\"\n",
    "        \n",
    "    taxi_trips_id = taxi_trips.merge(payment_type_master, on='payment_type')\n",
    "    taxi_trips_id = taxi_trips_id.merge(company_master, on='company')\n",
    "    taxi_trips_id.drop(['payment_type', 'company'], axis=1, inplace=True)\n",
    "    return taxi_trips_id\n",
    "    \n",
    "def upload_master_data_to_s3(bucket: str, path: str, file_type: str, dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to an S3 bucket as a master data file, while preserving the previous version of the master file.\n",
    "\n",
    "    This function performs the following operations:\n",
    "    1. Copies the existing master file to a backup location with a specified naming convention.\n",
    "    2. Converts the provided DataFrame to CSV format.\n",
    "    3. Uploads the new master file to the S3 bucket.\n",
    "\n",
    "    Parameters:\n",
    "    bucket (str): The name of the S3 bucket.\n",
    "    path (str): The path in the S3 bucket where the master file will be stored.\n",
    "    file_type (str): A string indicating the type of file, which is used to construct the master file's name.\n",
    "    dataframe (pd.DataFrame): The pandas DataFrame to be uploaded as the master file.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Raises:\n",
    "    botocore.exceptions.BotoCoreError: If an error is returned by the S3 service.\n",
    "    botocore.exceptions.ClientError: If a client error is returned by the S3 service.\n",
    "    \n",
    "    Example:\n",
    "    >>> import pandas as pd\n",
    "    >>> data = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "    >>> df = pd.DataFrame(data)\n",
    "    >>> upload_master_data_to_s3('my-bucket', 'data/', 'example', df)\n",
    "    \"\"\"\n",
    "    \n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    master_file_path = f'{path}{file_type}_master.csv'\n",
    "    previous_master_file_path = f'transformed_data/master_table_previous_version/{file_type}_master_previous_version.csv'\n",
    "    \n",
    "    s3.copy_object(\n",
    "            Bucket = bucket,\n",
    "            CopySource = {\"Bucket\": bucket, \"Key\": master_file_path},\n",
    "            Key = previous_master_file_path\n",
    "        )\n",
    "\n",
    "    buffer = StringIO()\n",
    "    dataframe.to_csv(buffer, index=False)\n",
    "    df_content = buffer.getvalue()\n",
    "    s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Key=master_file_path,\n",
    "        Body=df_content\n",
    "        )\n",
    "\n",
    "\n",
    "def upload_and_move_file_on_s3(dataframe: pd.DataFrame, datetime_col: str, bucket: str, target_path_transformed: str, file_type: str, source_path:str, target_path_raw: str, filename: str):\n",
    "    \"\"\"\n",
    "    Uploads a pandas DataFrame to a specified S3 bucket location, then moves the source file to a different location within the same bucket.\n",
    "\n",
    "    This function performs the following operations:\n",
    "    1. Formats the `datetime_col` of the DataFrame to create a timestamped filename.\n",
    "    2. Converts the DataFrame to CSV format and uploads it to the specified target path.\n",
    "    3. Copies the original file from the source path to the target raw path.\n",
    "    4. Deletes the original file from the source path after copying.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The pandas DataFrame to be uploaded.\n",
    "    datetime_col (str): The column name in the DataFrame containing datetime values used for timestamping the filename.\n",
    "    bucket (str): The name of the S3 bucket.\n",
    "    target_path_transformed (str): The S3 path where the transformed CSV file will be uploaded.\n",
    "    file_type (str): The type of file, used to construct the filename.\n",
    "    source_path (str): The S3 path of the original file.\n",
    "    target_path_raw (str): The S3 path where the original file will be moved.\n",
    "    filename (str): The name of the original file.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Raises:\n",
    "    botocore.exceptions.BotoCoreError: If an error is returned by the S3 service.\n",
    "    botocore.exceptions.ClientError: If a client error is returned by the S3 service.\n",
    "\n",
    "    Example:\n",
    "    >>> import pandas as pd\n",
    "    >>> from datetime import datetime\n",
    "    >>> data = {'datetime_col': [datetime(2023, 9, 6)], 'col1': [1], 'col2': [2]}\n",
    "    >>> df = pd.DataFrame(data)\n",
    "    >>> upload_and_move_file_on_s3(df, 'datetime_col', 'my-bucket', 'transformed_data/taxi_trips/', 'taxi_trips', 'source_path/', 'target_path_raw/', 'source_file.csv')\n",
    "    \"\"\"\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    formatted_date = dataframe[datetime_col].iloc[0].strftime('%Y-%m-%d')\n",
    "    new_path_with_filename = f'{target_path_transformed}{file_type}_{formatted_date}.csv'\n",
    "    #A filenév a köv. lesz:\n",
    "    # target_path_transformed =  transformed_data/taxi_trips/\n",
    "    # file_type = taxi_trips\n",
    "    # transformed_data/taxi_trips/taxi_trips_2023-09-06.csv\n",
    "    \n",
    "    buffer = StringIO()\n",
    "    dataframe.to_csv(buffer, index=False)\n",
    "    df_content = buffer.getvalue()\n",
    "    s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Key=new_path_with_filename,\n",
    "        Body=df_content\n",
    "        )\n",
    "    \n",
    "    s3.copy_object(\n",
    "        Bucket = bucket,\n",
    "        CopySource = {\"Bucket\": bucket, \"Key\": f'{source_path}{filename}'},\n",
    "        Key = f'{target_path_raw}{filename}'\n",
    "    )\n",
    "    \n",
    "    s3.delete_object(Bucket=bucket, Key = f'{source_path}{filename}')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    bucket = 'chicago-taxi'\n",
    "    \n",
    "    raw_weather_folder = 'raw_data/to_processed/weather_data/'\n",
    "    raw_taxi_trips_folder = 'raw_data/to_processed/taxi_data/'\n",
    "    \n",
    "    target_taxi_trips_folder ='raw_data/processed/taxi_data/'\n",
    "    target_weather_folder = 'raw_data/processed/weather_data/'\n",
    "    \n",
    "    payment_type_master_folder = 'transformed_data/payment_type/'\n",
    "    payment_type_master_file = 'payment_type_master.csv'\n",
    "    \n",
    "    company_master_folder = 'transformed_data/company/'\n",
    "    company_master_file = 'company_master.csv'\n",
    "\n",
    "    transformed_taxi_trips_folder = 'transformed_data/taxi_trips/'\n",
    "    transformed_weather_folder = 'transformed_data/weather/'\n",
    "    \n",
    "\n",
    "    payment_type_master = read_csv_from_s3(bucket=bucket, path=payment_type_master_folder, filename=payment_type_master_file)\n",
    "    company_master = read_csv_from_s3(bucket=bucket, path=company_master_folder, filename=company_master_file)\n",
    "    \n",
    "    file_name_for_testing_taxi_trips = 'taxi_raw2024-03-15.json'\n",
    "    file_name_for_testing_weather = 'weather_raw2024-03-15.json'\n",
    "    \n",
    "    #Taxi data transformation and loading\n",
    "    for file in s3.list_objects(Bucket = bucket, Prefix = raw_taxi_trips_folder)['Contents']:\n",
    "        taxi_trip_key = file['Key']\n",
    "        if taxi_trip_key.split('/')[-1].strip() != '':\n",
    "            if taxi_trip_key.split('.')[1] == 'json':\n",
    "                filename = taxi_trip_key.split('/')[-1].strip()\n",
    "                \n",
    "                response = s3.get_object(Bucket = bucket, Key = taxi_trip_key)\n",
    "                content = response['Body']\n",
    "                taxi_trips_data_json = json.loads(content.read())\n",
    "                \n",
    "                taxi_trips_data_raw = pd.DataFrame(taxi_trips_data_json)\n",
    "                taxi_trips_transformed = taxi_trips_transformations(taxi_trips_data_raw)\n",
    "                \n",
    "                #company_master_updated = update_master(taxi_trips_transformed, company_master, 'company_id', 'company')\n",
    "                payment_type_master_updated = update_master(taxi_trips_transformed, payment_type_master,'payment_type_id', 'payment_type')\n",
    "                \n",
    "                taxi_trips = update_taxi_trips_with_master_data(taxi_trips_transformed, payment_type_master_updated, company_master_updated)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                    dataframe=taxi_trips, \n",
    "                    datetime_col='datetime_for_weather', \n",
    "                    bucket=bucket, \n",
    "                    target_path_transformed=transformed_taxi_trips_folder, \n",
    "                    file_type='taxi', \n",
    "                    source_path=raw_taxi_trips_folder, \n",
    "                    target_path_raw=target_taxi_trips_folder, \n",
    "                    filename=filename)\n",
    "                print('Taxi trips is uploaded.')\n",
    "                \n",
    "                upload_master_data_to_s3(bucket=bucket, path=payment_type_master_folder, file_type='payment_type', dataframe=payment_type_master_updated)\n",
    "                print('Payment has been updated')\n",
    "                upload_master_data_to_s3(bucket=bucket, path=company_master_folder, file_type='company', dataframe=company_master_updated)\n",
    "                print('company updated')\n",
    "    \n",
    "    \n",
    "\n",
    "    #Weather data trandform and loading\n",
    "    for file in s3.list_objects(Bucket = bucket, Prefix = raw_weather_folder)['Contents']:\n",
    "        weather_key = file['Key']\n",
    "        \n",
    "        if weather_key.split('/')[-1].strip() != '':\n",
    "            if weather_key.split('.')[1] == 'json':\n",
    "                filename = weather_key.split('/')[-1].strip()\n",
    "                \n",
    "                response = s3.get_object(Bucket = bucket, Key = weather_key)\n",
    "                content = response['Body']\n",
    "                weather_data_json = json.loads(content.read())\n",
    "                \n",
    "                weather_data = transform_weather_data(weather_data_json)\n",
    "                \n",
    "                upload_and_move_file_on_s3(\n",
    "                    dataframe=weather_data, \n",
    "                    datetime_col='datetime', \n",
    "                    bucket=bucket, \n",
    "                    target_path_transformed=transformed_weather_folder, \n",
    "                    file_type='weather', \n",
    "                    source_path=raw_weather_folder, \n",
    "                    target_path_raw=target_weather_folder, \n",
    "                    filename=filename)\n",
    "                print('Taxi trips is uploaded.')\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
